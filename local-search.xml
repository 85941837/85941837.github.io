<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>张量的基本操作</title>
    <link href="/2024/11/02/1.%E5%BC%A0%E9%87%8F%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"/>
    <url>/2024/11/02/1.%E5%BC%A0%E9%87%8F%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h2 id="一-张量的基础概念"><a href="#一-张量的基础概念" class="headerlink" title="一. 张量的基础概念"></a>一. 张量的基础概念</h2><p>在学深度学习里，<strong>Tensor实际上就是一个多维数组（multidimensional array）</strong>，是一种最基础的数据结构。</p><h2 id="二-张量常用操作"><a href="#二-张量常用操作" class="headerlink" title="二. 张量常用操作"></a>二. 张量常用操作</h2><h4 id="访问某一个元素（最后一个跳跃访问，每三行访问一个元素，每两列访问一个元素）"><a href="#访问某一个元素（最后一个跳跃访问，每三行访问一个元素，每两列访问一个元素）" class="headerlink" title="访问某一个元素（最后一个跳跃访问，每三行访问一个元素，每两列访问一个元素）"></a><strong>访问某一个元素（最后一个跳跃访问，每三行访问一个元素，每两列访问一个元素）</strong></h4><p><img src="/../imgs/1.%E5%BC%A0%E9%87%8F%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/1715695979821-5ddedfb0-17de-4ac8-a7b8-8361a8c60ea9.webp" alt="image-20240514215004991.png"></p><p><strong>构造一个张量：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br>a = torch.ones(<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><p><strong>使用ndim查看张量的维度：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t1 = torch.tensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>])<br>t1.ndim <br></code></pre></td></tr></table></figure><p>输出：1</p><p><strong>使用shape查看形状</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t1 = torch.tensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>])<br>t1.shape<br></code></pre></td></tr></table></figure><p><strong>由两个形状相同的二维数组创建一个三维的张量</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">a1 = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">4</span>]])<br>a2 = np.array([[<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">6</span>],[<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">8</span>]])<br>t3 = torch.tensor([a1,a2])<br></code></pre></td></tr></table></figure><p>输出：结果是一个三位向量</p><p>tensor([[[1, 2, 2],<br>[3, 4, 4]],<br>[[5, 6, 6],<br>[7, 8, 8]]], dtype&#x3D;torch.int32)</p><p><strong>flatten拉平，将任意维度张量转化为一维张量</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t2 = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],[<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])<br>t2.flatten()<br></code></pre></td></tr></table></figure><p>输出：</p><p>tensor([1, 2, 3, 4])</p><p><strong>reshape方法，任意变形</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t1 = torch.tensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>])<br>t1.reshape(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p>输出：</p><p>tensor([[1],[2]])</p><p>torch.Size([2, 1])</p><p><strong>特殊张量创建：****全零张量 .zeros()、全1张量 .ones()、单位矩阵 .eyes()、对角矩阵 .diag(一维张量)</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.eye(<span class="hljs-number">5</span>)<br>t1 = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>])<br>torch.diag(t1)<br></code></pre></td></tr></table></figure><p>输出：</p><p>tensor([[1., 0., 0., 0., 0.],<br>[0., 1., 0., 0., 0.],<br>[0., 0., 1., 0., 0.],<br>[0., 0., 0., 1., 0.],<br>[0., 0., 0., 0., 1.]])</p><p>tensor([[1, 0],</p><p>[0, 2]])</p><p><strong>服从0-1均匀分布的张量rand</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.randn(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)<span class="hljs-comment">#2行3列的随机数所构成的张量</span><br></code></pre></td></tr></table></figure><p>输出：</p><p>tensor([[-0.8110, -1.1295, -0.2913],<br>[-1.1786, -0.8882, 0.2433]])</p><p><strong>arange&#x2F;linspace:生成数列</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.arange(<span class="hljs-number">5</span>)<br>torch.arange(<span class="hljs-number">1</span>,<span class="hljs-number">5</span>,<span class="hljs-number">0.5</span>) <span class="hljs-comment">#从1到5，每隔0.5取一个数</span><br>torch.linspace(<span class="hljs-number">1</span>,<span class="hljs-number">5</span>,<span class="hljs-number">3</span>) <span class="hljs-comment">#从1取到5，等距取三个数</span><br></code></pre></td></tr></table></figure><p><strong>empty，初始化指定形状矩阵</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.full([<span class="hljs-number">2</span>,<span class="hljs-number">4</span>],<span class="hljs-number">2</span>) <span class="hljs-comment">#2行4列，数值为2</span><br></code></pre></td></tr></table></figure><p>输出：</p><p>tensor([[2, 2, 2, 2],<br>[2, 2, 2, 2]])</p><p><strong>创建指定形状的数组</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.full_like(t1,<span class="hljs-number">2</span>) <span class="hljs-comment">#根据t1的形状，填充数值2</span><br>torch.randint_like(t2,<span class="hljs-number">1</span>,<span class="hljs-number">10</span>) <span class="hljs-comment">#在1到10中随机抽取一些整数，并将其填充进t2的形状中去</span><br></code></pre></td></tr></table></figure><p><strong>张量与其它相关类型(数组、列表)之间转化方法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">t1 = torch.tensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>,<span class="hljs-number">10</span>])<br>t1.numpy()<br>t1.tolist()<br></code></pre></td></tr></table></figure><p>输出：</p><p>array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype&#x3D;int64)</p><p>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</p><p><strong>切片，一小点需要注意</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">t2[[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>],<span class="hljs-number">1</span>] <span class="hljs-comment"># 第一行和第3行的第2列元素</span><br></code></pre></td></tr></table></figure><p><strong>分块</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tc = torch.chunk(t2,<span class="hljs-number">4</span>,dim=<span class="hljs-number">0</span>) <br></code></pre></td></tr></table></figure><p>输出：<br>(tensor([[0, 1, 2]]),<br>tensor([[3, 4, 5]]),<br>tensor([[6, 7, 8]]),<br>tensor([[ 9, 10, 11]]))</p><p><strong>拆分****：split函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t2 = torch.arange(<span class="hljs-number">12</span>).reshape(<span class="hljs-number">4</span>,<span class="hljs-number">3</span>)<br>torch.split(t2,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>)  <br></code></pre></td></tr></table></figure><p>输出：</p><p>(tensor([[0, 1, 2],<br>[3, 4, 5]]),<br>tensor([[ 6, 7, 8],<br>[ 9, 10, 11]]))</p><p>torch.split(t2,[1,3],0)</p><p>[1,3]表示“第一块长度为1，第二块长度为3</p><p><strong>torch.cat 的用法：多个张量合并在一起,默认按行(dim&#x3D;0)【记住二维张量dim&#x3D;0表示行】进行拼接，维度不匹配会报错</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">z = torch.arange(<span class="hljs-number">12</span>, dtype=torch.float32).reshape(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>)<br>k = torch.tensor([[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>,<span class="hljs-number">1</span>]])<br>h = torch.cat((z,k), dim=<span class="hljs-number">0</span>), torch.cat((z,k), dim=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(h)<br><br>输出：<br>(tensor([[ <span class="hljs-number">0.</span>,  <span class="hljs-number">1.</span>,  <span class="hljs-number">2.</span>,  <span class="hljs-number">3.</span>],<br>        [ <span class="hljs-number">4.</span>,  <span class="hljs-number">5.</span>,  <span class="hljs-number">6.</span>,  <span class="hljs-number">7.</span>],<br>        [ <span class="hljs-number">8.</span>,  <span class="hljs-number">9.</span>, <span class="hljs-number">10.</span>, <span class="hljs-number">11.</span>],<br>        [ <span class="hljs-number">2.</span>,  <span class="hljs-number">3.</span>,  <span class="hljs-number">4.</span>,  <span class="hljs-number">1.</span>],<br>        [ <span class="hljs-number">4.</span>,  <span class="hljs-number">5.</span>,  <span class="hljs-number">6.</span>,  <span class="hljs-number">1.</span>],<br>        [ <span class="hljs-number">7.</span>,  <span class="hljs-number">8.</span>,  <span class="hljs-number">9.</span>,  <span class="hljs-number">1.</span>]]),<br> tensor([[ <span class="hljs-number">0.</span>,  <span class="hljs-number">1.</span>,  <span class="hljs-number">2.</span>,  <span class="hljs-number">3.</span>,  <span class="hljs-number">2.</span>,  <span class="hljs-number">3.</span>,  <span class="hljs-number">4.</span>,  <span class="hljs-number">1.</span>],<br>        [ <span class="hljs-number">4.</span>,  <span class="hljs-number">5.</span>,  <span class="hljs-number">6.</span>,  <span class="hljs-number">7.</span>,  <span class="hljs-number">4.</span>,  <span class="hljs-number">5.</span>,  <span class="hljs-number">6.</span>,  <span class="hljs-number">1.</span>],<br>        [ <span class="hljs-number">8.</span>,  <span class="hljs-number">9.</span>, <span class="hljs-number">10.</span>, <span class="hljs-number">11.</span>,  <span class="hljs-number">7.</span>,  <span class="hljs-number">8.</span>,  <span class="hljs-number">9.</span>,  <span class="hljs-number">1.</span>]]))<br></code></pre></td></tr></table></figure><p>【-1】访问最后一个元素，【1：3】选择第一行和第二行的元素（左闭右开）</p><p><strong>张量的维度变化</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">x = torch.randn(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>)<br>输出:<br>tensor([[ <span class="hljs-number">0.6480</span>, <span class="hljs-number">1.5947</span>, <span class="hljs-number">0.6264</span>, <span class="hljs-number">0.6051</span>],<br>[ <span class="hljs-number">1.6784</span>, <span class="hljs-number">0.2768</span>, -<span class="hljs-number">1.8780</span>, -<span class="hljs-number">0.1133</span>],<br>[-<span class="hljs-number">0.6442</span>, <span class="hljs-number">0.8570</span>, <span class="hljs-number">0.1677</span>, <span class="hljs-number">0.2378</span>]])<br>mask = x.ge(<span class="hljs-number">0.5</span>)<br>输出：<br>tensor([[ <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>],<br>[ <span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>],<br>[<span class="hljs-literal">False</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>]])<br><br>torch.masked_select(x,mask) <br>输出：<br>tensor([<span class="hljs-number">0.6480</span>, <span class="hljs-number">1.5947</span>, <span class="hljs-number">0.6264</span>, <span class="hljs-number">0.6051</span>, <span class="hljs-number">1.6784</span>, <span class="hljs-number">0.8570</span>])<br></code></pre></td></tr></table></figure><p><strong>删除不必要的维度</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t = torch.zeros(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>)<br>torch.squeeze(t).shape<span class="hljs-comment">#剔除所有属性为1的维度</span><br></code></pre></td></tr></table></figure><p>输出：</p><p>torch.Size([3])</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">b.squeeze(<span class="hljs-number">0</span>).shape <span class="hljs-comment">#挤压掉第0维</span><br>b.squeeze(-<span class="hljs-number">1</span>).shape  <span class="hljs-comment">#挤压掉最后一维</span><br>b.squeeze(<span class="hljs-number">1</span>).shape <span class="hljs-comment">#挤压掉第一维</span><br></code></pre></td></tr></table></figure><p><strong>unsqueeze手动升维</strong></p><p>调用方法1：torch.unsqueeze(t, dim&#x3D;n)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">t = torch.zeros(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br><span class="hljs-comment"># 在第0位索引上升高一个维度变成五维</span><br>torch.unsqueeze(t,dim=<span class="hljs-number">0</span>).shape <br></code></pre></td></tr></table></figure><p>输出：</p><p>torch.Size([1, 1, 2, 1, 2])</p><p>调用方法2：a.unsqueeze(dim&#x3D;n)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 在0索引前面插入了一个额外的维度</span><br>a.unsqueeze(<span class="hljs-number">0</span>).shape <br><span class="hljs-comment"># 在末尾插入一个额外的维度，可以理解为像素的属性</span><br>a.unsqueeze(-<span class="hljs-number">1</span>).shape <br></code></pre></td></tr></table></figure><p><strong>expand:broadcasting #只改变理解方式，不增加数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">b = torch.rand(<span class="hljs-number">1</span>,<span class="hljs-number">32</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>b.expand(<span class="hljs-number">4</span>,<span class="hljs-number">32</span>,<span class="hljs-number">14</span>,<span class="hljs-number">14</span>).shape   <br></code></pre></td></tr></table></figure><p>输出：</p><p>torch.Size([4, 32, 14, 14])</p><p><strong>repeat的参数表示重复的次数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 4表示对0维重复4次，32表示对1维重复32次</span><br>b.repeat(<span class="hljs-number">4</span>,<span class="hljs-number">32</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>).shape<br></code></pre></td></tr></table></figure><p>输出：</p><p>torch.Size([4, 1024, 1, 1])</p><p><strong>矩阵转置</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.randn(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>)<br>a.shape<br>a.t()<br></code></pre></td></tr></table></figure><p>输出：</p><p>torch.Size([4, 3])</p><p><strong>维度转换</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># transpose实现维度两两交换</span><br>a = torch.rand(<span class="hljs-number">4</span>,<span class="hljs-number">3</span>,<span class="hljs-number">32</span>,<span class="hljs-number">32</span>)<br><span class="hljs-number">2</span> = a.transpose(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>).contiguous().view(<span class="hljs-number">4</span>,<span class="hljs-number">3</span>*<span class="hljs-number">32</span>*<span class="hljs-number">32</span>).view(<span class="hljs-number">4</span>,<span class="hljs-number">32</span>,<span class="hljs-number">32</span>,<span class="hljs-number">3</span>).transpose(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><p>解释：</p><p>#transpose包含了要交换的两个维度[b,c,h,w]→[b,w,h,c]</p><p>#数据的维度顺序必须与存储顺序一致,用.contiguous把数据变成连续的</p><p>#.view(4,33232) [b,whc]</p><p>#.view(4,3,32,32) [b,w,h,c]</p><p>#.transpose(1,3) [b,c,g,w]</p><p><strong>permute维度转换</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">b = torch.rand(<span class="hljs-number">4</span>,<span class="hljs-number">3</span>,<span class="hljs-number">28</span>,<span class="hljs-number">32</span>) <br>b.permute(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>).shape    <br></code></pre></td></tr></table></figure><p>输出：</p><p>torch.Size([4, 28, 32, 3])</p>]]></content>
    
    
    <categories>
      
      <category>pytorch基础</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
